import os
import logging
from typing import List, Dict, Optional
from pathlib import Path

import chromadb  # <--- –ù–æ–≤–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞
from openai import AsyncOpenAI

# from pinecone import Pinecone # <--- –£–¥–∞–ª–µ–Ω–æ

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞
logger = logging.getLogger(__name__)

# === 1. –ù–ê–°–¢–†–û–ô–ö–ê –ü–£–¢–ï–ô –ò –ö–õ–ò–ï–ù–¢–û–í ===

# –í—ã—á–∏—Å–ª—è–µ–º –ø—É—Ç—å –∫ –∫–æ—Ä–Ω—é –ø—Ä–æ–µ–∫—Ç–∞.
# –§–∞–π–ª –ª–µ–∂–∏—Ç –≤: app/services/search_service.py
# .parent -> app/services
# .parent.parent -> app
# .parent.parent.parent -> –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ (–≥–¥–µ –ª–µ–∂–∏—Ç –ø–∞–ø–∫–∞ chromadb_storage)
BASE_DIR = Path(__file__).resolve().parent.parent.parent
CHROMA_DB_PATH = os.path.join(BASE_DIR, "chromadb_storage")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI
openai_client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ChromaDB
# PersistentClient = –±–∞–∑–∞ –Ω–∞ –¥–∏—Å–∫–µ (–Ω–µ –≤ –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–π –ø–∞–º—è—Ç–∏)
chroma_client = chromadb.PersistentClient(path=CHROMA_DB_PATH)
collection = chroma_client.get_or_create_collection(name="strollers")

# === 2. –°–õ–û–í–ê–†–¨-–ü–ï–†–ï–í–û–î–ß–ò–ö ===
QUIZ_TRANSLATIONS = {
    # –¢–∏–ø –∫–æ–ª—è—Å–∫–∏
    "from_birth": "–∫–æ–ª—è—Å–∫–∞ –¥–ª—è –Ω–æ–≤–æ—Ä–æ–∂–¥–µ–Ω–Ω–æ–≥–æ",
    "stroller": "–ø—Ä–æ–≥—É–ª–æ—á–Ω–∞—è –∫–æ–ª—è—Å–∫–∞ –¥–ª—è –¥–µ—Ç–µ–π –æ—Ç 6 –º–µ—Å—è—Ü–µ–≤",
    "service_only": "–∫–æ–ª—è—Å–∫–∞",

    # –ü–æ–¥—Ç–∏–ø –∫–æ–ª—è—Å–∫–∏
    "stroller_folds_like_a_cane": "–∫–æ–ª—è—Å–∫–∞-—Ç—Ä–æ—Å—Ç—å, –º–µ—Ö–∞–Ω–∏–∑–º —Å–∫–ª–∞–¥—ã–≤–∞–Ω–∏—è –ø–æ —Ç–∏–ø—É —Ç—Ä–æ—Å—Ç—å",
    "The_child's_age_is_from_6_months": "–º–µ—Ö–∞–Ω–∏–∑–º —Å–∫–ª–∞–¥—ã–≤–∞–Ω–∏—è –ø–æ —Ç–∏–ø—É –∫–Ω–∏–∂–∫–∞",

    # –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª
    "2in1": "–∫–æ–ª—è—Å–∫–∞ 2 –≤ 1 —Å –ª—é–ª—å–∫–æ–π",
    "3in1": "–∫–æ–ª—è—Å–∫–∞ 3 –≤ 1 —Å –∞–≤—Ç–æ–∫—Ä–µ—Å–ª–æ–º",
    "transformer": "–∫–æ–ª—è—Å–∫–∞-—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä, –ª—é–ª—å–∫–∞-—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä",

    # –°—Ü–µ–Ω–∞—Ä–∏–π
    "daily_walks": "–î–ª—è –µ–∂–µ–¥–Ω–µ–≤–Ω—ã—Ö –ø—Ä–æ–≥—É–ª–æ–∫",
    "car_trips": "–¥–ª—è —É–¥–æ–±–Ω–æ–π –ø–µ—Ä–µ–≤–æ–∑–∫–∏ –≤ –∞–≤—Ç–æ–º–æ–±–∏–ª–µ, —Å–∫–ª–∞–¥—ã–≤–∞–Ω–∏–µ –æ–¥–Ω–æ–π —Ä—É–∫–æ–π",
    "air_travel": "–¥–ª—è –ø—É—Ç–µ—à–µ—Å—Ç–≤–∏–π –∏ –∞–≤–∏–∞–ø–µ—Ä–µ–ª–µ—Ç–æ–≤, –ª–µ–≥–∫–∞—è –∫–æ–º–ø–∞–∫—Ç–Ω–∞—è –¥–ª—è —Å–∞–º–æ–ª–µ—Ç–∞ —Ä—É—á–Ω–∞—è –∫–ª–∞–¥—å",

    # –°–µ–∑–æ–Ω
    "summer": "–ª–µ—Ç–Ω—è—è —Å –≤–µ–Ω—Ç–∏–ª—è—Ü–∏–µ–π",
    "winter": "—Ç–µ–ø–ª–∞—è –∑–∏–º–Ω—è—è –Ω–µ–ø—Ä–æ–¥—É–≤–∞–µ–º–∞—è (—Ç–µ—Ä–º–æ–ª—é–ª—å–∫–∞), –∑–∞—â–∏—Ç–∞ –æ—Ç–≤–µ—Ç—Ä–∞",

    # –¢–∏–ø –¥–æ—Ä–æ–≥–∏
    "ground": "–¥–ª—è –µ–∑–¥—ã –ø–æ –≥—Ä—É–Ω—Ç—É, —Å—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –∫–æ–ª–µ—Å, —Ö–æ—Ä–æ—à–∞—è –∞–º–æ—Ä—Ç–∏–∑–∞—Ü–∏—è",
    "asphalt": "–¥–ª—è –µ–∑–¥—ã –ø–æ –∞—Å—Ñ–∞–ª—å—Ç—É, –º–∞–Ω–µ–≤—Ä–µ–Ω–Ω–∞—è –≥–æ—Ä–æ–¥—Å–∫–∞—è –∫–æ–ª—è—Å–∫–∞, –ª–µ–≥–∫–∞—è",
    "ground and asphalt": "–¥–ª—è –µ–∑–¥—ã –∫–∞–∫ –ø–æ –∞—Å—Ñ–∞–ª—å—Ç—É —Ç–∞–∫ –∏ –ø–æ –≥—Ä—É–Ω—Ç—É, —Å—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –∫–æ–ª–µ—Å, —Ö–æ—Ä–æ—à–∞—è –∞–º–æ—Ä—Ç–∏–∑–∞—Ü–∏—è",
    "offroad and snow": "–¥–ª—è –µ–∑–¥—ã –ø–æ –±–µ–∑–¥–æ—Ä–æ–∂—å—é –∏ —Å–Ω–µ–≥—É, –≤–µ–∑–¥–µ—Ö–æ–¥ —Å –±–æ–ª—å—à–∏–º–∏ –∫–æ–ª—ë—Å–∞–º–∏ –∏ –æ—Ç–ª–∏—á–Ω–æ–π –∞–º–æ—Ä—Ç–∏–∑–∞—Ü–∏–µ–π",
}


async def get_query_embedding(text: str) -> List[float]:
    """–ü—Ä–µ–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –≤ –≤–µ–∫—Ç–æ—Ä"""
    try:
        response = await openai_client.embeddings.create(
            model="text-embedding-3-small",
            input=text
        )
        return response.data[0].embedding
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
        return []


def translate_quiz_to_text(quiz_data: dict) -> str:
    """–ü—Ä–µ–≤—Ä–∞—â–∞–µ—Ç JSON –∫–≤–∏–∑–∞ –≤ –ø–æ–∏—Å–∫–æ–≤—É—é —Å—Ç—Ä–æ–∫—É –Ω–∞ —Ä—É—Å—Å–∫–æ–º."""
    search_terms = []
    for key, value in quiz_data.items():
        if value in QUIZ_TRANSLATIONS:
            search_terms.append(QUIZ_TRANSLATIONS[value])
        elif key in QUIZ_TRANSLATIONS:
            search_terms.append(QUIZ_TRANSLATIONS[key])
        elif isinstance(value, str):
            search_terms.append(value)
    return " ".join(search_terms)


# async def search_products(
#         user_query: str,
#         quiz_json: Optional[dict] = None,
#         magazine_id: Optional[int] = None,
#         top_k: int = 10
# ) -> str:
#     """
#     –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ (–ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–æ –ø–æ–¥ ChromaDB).
#     """
#
#     # 1. –§–æ—Ä–º–∏—Ä—É–µ–º "–ò–¥–µ–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å"
#     full_search_text = user_query
#     if quiz_json:
#         translated_quiz = translate_quiz_to_text(quiz_json)
#         full_search_text = f"{full_search_text} {translated_quiz}"
#
#     logger.info(f"üîé –ò—â–µ–º –≤ ChromaDB –ø–æ —Ñ—Ä–∞–∑–µ: '{full_search_text}' (Mag ID: {magazine_id})")
#
#     # 2. –ü–æ–ª—É—á–∞–µ–º –≤–µ–∫—Ç–æ—Ä
#     vector = await get_query_embedding(full_search_text)
#     if not vector:
#         return ""
#
#     try:
#         # 3. –ó–∞–ø—Ä–æ—Å –≤ –±–∞–∑—É ChromaDB
#         # –ú—ã –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —á—É—Ç—å –±–æ–ª—å—à–µ (top_k * 2), —á—Ç–æ–±—ã –µ—Å–ª–∏ Python-—Ñ–∏–ª—å—Ç—Ä
#         # –æ—Ç—Å–µ–µ—Ç —á—É–∂–∏–µ –º–∞–≥–∞–∑–∏–Ω—ã, —É –Ω–∞—Å –æ—Å—Ç–∞–ª–∏—Å—å –≤–∞—Ä–∏–∞–Ω—Ç—ã.
#         # –ï—Å–ª–∏ magazine_id –Ω–µ—Ç (–ø–æ–∏—Å–∫ –ø–æ –≤—Å–µ–º) - –±–µ—Ä–µ–º —Ä–æ–≤–Ω–æ top_k.
#         fetch_k = top_k * 2 if magazine_id else top_k
#
#         results = collection.query(
#             query_embeddings=[vector],
#             n_results=fetch_k
#         )
#
#         # Chroma –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É: {'ids': [[]], 'metadatas': [[]], 'distances': [[]]}
#         # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
#         if not results['ids'] or not results['ids'][0]:
#             return ""
#
#         # 4. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è
#         context_text = ""
#         found_count = 0
#
#         # –î–∞–Ω–Ω—ã–µ –ø–µ—Ä–≤–æ–≥–æ (–∏ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ) –∑–∞–ø—Ä–æ—Å–∞
#         metadatas_list = results['metadatas'][0]
#         distances_list = results['distances'][0]  # –ß–µ–º –º–µ–Ω—å—à–µ, —Ç–µ–º –ª—É—á—à–µ (–≤ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–∏ Chroma)
#
#         for i, meta in enumerate(metadatas_list):
#             if found_count >= top_k:
#                 break
#
#             # --- Python-—Ñ–∏–ª—å—Ç—Ä –ø–æ –º–∞–≥–∞–∑–∏–Ω—É ---
#             # –í update_vectors –º—ã —Å–æ—Ö—Ä–∞–Ω—è–ª–∏ "magazine_ids_str": "1,2,5"
#             if magazine_id:
#                 allowed_ids_str = meta.get("magazine_ids_str", "")
#                 allowed_ids = allowed_ids_str.split(",")
#                 # –ï—Å–ª–∏ —Ç–µ–∫—É—â–µ–≥–æ –º–∞–≥–∞–∑–∏–Ω–∞ –Ω–µ—Ç –≤ —Å–ø–∏—Å–∫–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã—Ö –¥–ª—è —ç—Ç–æ–≥–æ —Ç–æ–≤–∞—Ä–∞ - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
#                 if str(magazine_id) not in allowed_ids:
#                     continue
#
#             # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
#             name = meta.get('name', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')
#             price = meta.get('price', '–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞')
#             url = meta.get('url', '#')
#             # –û–±—Ä–µ–∑–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ
#             desc = meta.get('description', '')[:3000]
#
#             # üî• –í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–ê –†–ï–õ–ï–í–ê–ù–¢–ù–û–°–¢–¨ üî•
#             # –í Chroma —á–µ–º –º–µ–Ω—å—à–µ distance, —Ç–µ–º –ª—É—á—à–µ (0 = –∫–æ–ø–∏—è).
#             # –ü—Ä–µ–≤—Ä–∞—â–∞–µ–º –≤ % —Å—Ö–æ–∂–µ—Å—Ç–∏: (1 - distance) * 100
#             dist = distances_list[i]
#             # –ó–∞—â–∏—Ç–∞ –æ—Ç –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö —á–∏—Å–µ–ª (–µ—Å–ª–∏ –≤–µ–∫—Ç–æ—Ä—ã —Å—Ç—Ä–∞–Ω–Ω—ã–µ), —Ö–æ—Ç—è –æ–±—ã—á–Ω–æ distance <= 1
#             similarity = max(0.0, 1.0 - dist)
#             relevance_percent = int(similarity * 100)
#
#             context_text += (
#                 f"- <b>{name}</b>\n"
#                 f"  –¶–µ–Ω–∞: {price} —Ä—É–±.\n"
#                 f"  –°—Å—ã–ª–∫–∞: {url}\n"
#                 f"  –û–ø–∏—Å–∞–Ω–∏–µ: {desc}...\n"
#                 f"  <i>(–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {relevance_percent}%)</i>\n\n"
#             )
#             found_count += 1
#
#         return context_text
#
#     except Exception as e:
#         logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ ChromaDB: {e}")
#         return ""



#üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•–î–ª—è —Ç–µ—Å—Ç–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏. –í–≤–µ—Ä—Ö—É —Ä–∞–±–æ—á–∞—è —Ñ—É–Ω–∫—Ü–∏—èüî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•üî•
async def search_products(
        user_query: str,
        quiz_json: Optional[dict] = None,
        magazine_id: Optional[int] = None,
        top_k: int = 10
) -> str:
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ (ChromaDB + –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å + PRINT DEBUG).
    """

    # 1. –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å
    full_search_text = user_query
    if quiz_json:
        translated_quiz = translate_quiz_to_text(quiz_json)
        full_search_text = f"{full_search_text} {translated_quiz}"

    # üî• –ó–ê–ú–ï–ù–ò–õ–ò logger –ù–ê print
    print(f"üîé –ò—â–µ–º –≤ ChromaDB –ø–æ —Ñ—Ä–∞–∑–µ: '{full_search_text}' (Mag ID: {magazine_id})")

    # 2. –í–µ–∫—Ç–æ—Ä
    vector = await get_query_embedding(full_search_text)
    if not vector:
        return ""

    try:
        # 3. –ó–∞–ø—Ä–æ—Å –≤ –±–∞–∑—É
        fetch_k = top_k * 2 if magazine_id else top_k

        results = collection.query(
            query_embeddings=[vector],
            n_results=fetch_k
        )

        if not results['ids'] or not results['ids'][0]:
            # üî• –ó–ê–ú–ï–ù–ò–õ–ò logger –ù–ê print
            print("‚ö†Ô∏è –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –±–∞–∑–µ.")
            return ""

        # 4. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        context_text = ""
        found_count = 0

        metadatas_list = results['metadatas'][0]
        distances_list = results['distances'][0]

        # üî• –ó–ê–ú–ï–ù–ò–õ–ò logger –ù–ê print
        print(f"\n--- üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û–ò–°–ö–ê ({len(metadatas_list)} —à—Ç) ---")

        for i, meta in enumerate(metadatas_list):
            if found_count >= top_k:
                break

            # –§–∏–ª—å—Ç—Ä –ø–æ –º–∞–≥–∞–∑–∏–Ω—É
            if magazine_id:
                allowed_ids_str = meta.get("magazine_ids_str", "")
                allowed_ids = allowed_ids_str.split(",")
                if str(magazine_id) not in allowed_ids:
                    continue

            name = meta.get('name', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')
            price = meta.get('price', '–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞')
            url = meta.get('url', '#')
            desc = meta.get('description', '')[:3000]

            # –†–∞—Å—á–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
            dist = distances_list[i]
            similarity = max(0.0, 1.0 - dist)
            relevance_percent = int(similarity * 100)

            # üî• –í–´–í–û–î –í –ö–û–ù–°–û–õ–¨ –ß–ï–†–ï–ó PRINT
            print(f"[{relevance_percent}%] {name} | {price} —Ä—É–±. | {url}")

            context_text += (
                f"- <b>{name}</b>\n"
                f"  –¶–µ–Ω–∞: {price} —Ä—É–±.\n"
                f"  –°—Å—ã–ª–∫–∞: {url}\n"
                f"  –û–ø–∏—Å–∞–Ω–∏–µ: {desc}...\n"
                f"  <i>(–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {relevance_percent}%)</i>\n\n"
            )
            found_count += 1

        # üî• –ó–ê–ú–ï–ù–ò–õ–ò logger –ù–ê print
        print("--------------------------------------------------\n")

        return context_text

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ ChromaDB: {e}")
        return ""