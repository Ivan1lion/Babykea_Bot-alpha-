import os
import re
import logging
import chromadb

from typing import List, Dict, Optional, Union
from pathlib import Path
from openai import AsyncOpenAI


# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞
logger = logging.getLogger(__name__)

# === 1. –ù–ê–°–¢–†–û–ô–ö–ê –ü–£–¢–ï–ô –ò –ö–õ–ò–ï–ù–¢–û–í ===

# –í—ã—á–∏—Å–ª—è–µ–º –ø—É—Ç—å –∫ –∫–æ—Ä–Ω—é –ø—Ä–æ–µ–∫—Ç–∞.
# –§–∞–π–ª –ª–µ–∂–∏—Ç –≤: app/services/search_service.py
# .parent -> app/services
# .parent.parent -> app
# .parent.parent.parent -> –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ (–≥–¥–µ –ª–µ–∂–∏—Ç –ø–∞–ø–∫–∞ chromadb_storage)
BASE_DIR = Path(__file__).resolve().parent.parent.parent
CHROMA_DB_PATH = os.path.join(BASE_DIR, "chromadb_storage")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI
openai_client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ChromaDB
# PersistentClient = –±–∞–∑–∞ –Ω–∞ –¥–∏—Å–∫–µ (–Ω–µ –≤ –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–π –ø–∞–º—è—Ç–∏)
chroma_client = chromadb.PersistentClient(path=CHROMA_DB_PATH)
collection = chroma_client.get_or_create_collection(name="strollers")

# === 2. –°–õ–û–í–ê–†–¨-–ü–ï–†–ï–í–û–î–ß–ò–ö ===
QUIZ_TRANSLATIONS = {
    # –¢–∏–ø –∫–æ–ª—è—Å–∫–∏
    "from_birth": "–∫–æ–ª—è—Å–∫–∞ –¥–ª—è –Ω–æ–≤–æ—Ä–æ–∂–¥–µ–Ω–Ω–æ–≥–æ",
    "stroller": "–ø—Ä–æ–≥—É–ª–æ—á–Ω–∞—è –∫–æ–ª—è—Å–∫–∞ –¥–ª—è –¥–µ—Ç–µ–π –æ—Ç 6 –º–µ—Å—è—Ü–µ–≤",
    "service_only": "–∫–æ–ª—è—Å–∫–∞",

    # –ü–æ–¥—Ç–∏–ø –∫–æ–ª—è—Å–∫–∏
    "stroller_folds_like_a_cane": "–∫–æ–ª—è—Å–∫–∞-—Ç—Ä–æ—Å—Ç—å, –º–µ—Ö–∞–Ω–∏–∑–º —Å–∫–ª–∞–¥—ã–≤–∞–Ω–∏—è –ø–æ —Ç–∏–ø—É —Ç—Ä–æ—Å—Ç—å",
    "The_child's_age_is_from_6_months": "–º–µ—Ö–∞–Ω–∏–∑–º —Å–∫–ª–∞–¥—ã–≤–∞–Ω–∏—è –ø–æ —Ç–∏–ø—É –∫–Ω–∏–∂–∫–∞",

    # –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª
    "2in1": "–∫–æ–ª—è—Å–∫–∞ 2 –≤ 1 —Å –ª—é–ª—å–∫–æ–π",
    "3in1": "–∫–æ–ª—è—Å–∫–∞ 3 –≤ 1 —Å –∞–≤—Ç–æ–∫—Ä–µ—Å–ª–æ–º",
    "transformer": "–∫–æ–ª—è—Å–∫–∞-—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä, –ª—é–ª—å–∫–∞-—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä",

    # –°—Ü–µ–Ω–∞—Ä–∏–π
    "daily_walks": "–î–ª—è –µ–∂–µ–¥–Ω–µ–≤–Ω—ã—Ö –ø—Ä–æ–≥—É–ª–æ–∫",
    "car_trips": "–¥–ª—è —É–¥–æ–±–Ω–æ–π –ø–µ—Ä–µ–≤–æ–∑–∫–∏ –≤ –∞–≤—Ç–æ–º–æ–±–∏–ª–µ, —Å–∫–ª–∞–¥—ã–≤–∞–Ω–∏–µ –æ–¥–Ω–æ–π —Ä—É–∫–æ–π",
    "air_travel": "–¥–ª—è –ø—É—Ç–µ—à–µ—Å—Ç–≤–∏–π –∏ –∞–≤–∏–∞–ø–µ—Ä–µ–ª–µ—Ç–æ–≤, –ª–µ–≥–∫–∞—è –∫–æ–º–ø–∞–∫—Ç–Ω–∞—è –¥–ª—è —Å–∞–º–æ–ª–µ—Ç–∞ —Ä—É—á–Ω–∞—è –∫–ª–∞–¥—å",

    # –°–µ–∑–æ–Ω
    "summer": "–ª–µ—Ç–Ω—è—è —Å –≤–µ–Ω—Ç–∏–ª—è—Ü–∏–µ–π",
    "winter": "—Ç–µ–ø–ª–∞—è –∑–∏–º–Ω—è—è –Ω–µ–ø—Ä–æ–¥—É–≤–∞–µ–º–∞—è (—Ç–µ—Ä–º–æ–ª—é–ª—å–∫–∞), –∑–∞—â–∏—Ç–∞ –æ—Ç–≤–µ—Ç—Ä–∞",

    # –¢–∏–ø –¥–æ—Ä–æ–≥–∏
    "ground": "–¥–ª—è –µ–∑–¥—ã –ø–æ –≥—Ä—É–Ω—Ç—É, —Å—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –∫–æ–ª–µ—Å, —Ö–æ—Ä–æ—à–∞—è –∞–º–æ—Ä—Ç–∏–∑–∞—Ü–∏—è",
    "asphalt": "–¥–ª—è –µ–∑–¥—ã –ø–æ –∞—Å—Ñ–∞–ª—å—Ç—É, –º–∞–Ω–µ–≤—Ä–µ–Ω–Ω–∞—è –≥–æ—Ä–æ–¥—Å–∫–∞—è –∫–æ–ª—è—Å–∫–∞, –ª–µ–≥–∫–∞—è",
    "ground and asphalt": "–¥–ª—è –µ–∑–¥—ã –∫–∞–∫ –ø–æ –∞—Å—Ñ–∞–ª—å—Ç—É —Ç–∞–∫ –∏ –ø–æ –≥—Ä—É–Ω—Ç—É, —Å—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –∫–æ–ª–µ—Å, —Ö–æ—Ä–æ—à–∞—è –∞–º–æ—Ä—Ç–∏–∑–∞—Ü–∏—è",
    "offroad and snow": "–¥–ª—è –µ–∑–¥—ã –ø–æ –±–µ–∑–¥–æ—Ä–æ–∂—å—é –∏ —Å–Ω–µ–≥—É, –≤–µ–∑–¥–µ—Ö–æ–¥ —Å –±–æ–ª—å—à–∏–º–∏ –∫–æ–ª—ë—Å–∞–º–∏ –∏ –æ—Ç–ª–∏—á–Ω–æ–π –∞–º–æ—Ä—Ç–∏–∑–∞—Ü–∏–µ–π",
}


async def get_query_embedding(text: str) -> List[float]:
    """–ü—Ä–µ–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –≤ –≤–µ–∫—Ç–æ—Ä"""
    try:
        response = await openai_client.embeddings.create(
            model="text-embedding-3-small",
            input=text
        )
        return response.data[0].embedding
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
        return []


def translate_quiz_to_text(quiz_data: dict) -> str:
    """–ü—Ä–µ–≤—Ä–∞—â–∞–µ—Ç JSON –∫–≤–∏–∑–∞ –≤ –ø–æ–∏—Å–∫–æ–≤—É—é —Å—Ç—Ä–æ–∫—É –Ω–∞ —Ä—É—Å—Å–∫–æ–º."""
    search_terms = []
    for key, value in quiz_data.items():
        if value in QUIZ_TRANSLATIONS:
            search_terms.append(QUIZ_TRANSLATIONS[value])
        elif key in QUIZ_TRANSLATIONS:
            search_terms.append(QUIZ_TRANSLATIONS[key])
        elif isinstance(value, str):
            search_terms.append(value)
    return " ".join(search_terms)


async def search_products(
        user_query: str,
        quiz_json: Optional[dict] = None,
        # üî• –¢–µ–ø–µ—Ä—å –ø—Ä–∏–Ω–∏–º–∞–µ–º: –æ–¥–∏–Ω ID (int), —Å–ø–∏—Å–æ–∫ ID (List[int]) –∏–ª–∏ None
        allowed_magazine_ids: Union[int, List[int], None] = None,
        top_k: int = 10
) -> str:
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ (–ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–æ –ø–æ–¥ ChromaDB + –ó–∞—â–∏—Ç–∞ –æ—Ç –¥—É–±–ª–µ–π).
    """

    # 1. –§–æ—Ä–º–∏—Ä—É–µ–º "–ò–¥–µ–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å"
    full_search_text = user_query
    if quiz_json:
        translated_quiz = translate_quiz_to_text(quiz_json)
        full_search_text = f"{full_search_text} {translated_quiz}"

    logger.info(f"üîé –ò—â–µ–º –≤ ChromaDB –ø–æ —Ñ—Ä–∞–∑–µ: '{full_search_text}' (IDs: {allowed_magazine_ids})")

    # 2. –ü–æ–ª—É—á–∞–µ–º –≤–µ–∫—Ç–æ—Ä
    vector = await get_query_embedding(full_search_text)
    if not vector:
        return ""

    try:
        # 3. –ó–∞–ø—Ä–æ—Å –≤ –±–∞–∑—É ChromaDB
        # üî• –ë–µ—Ä–µ–º –≤ 4 —Ä–∞–∑–∞ –±–æ–ª—å—à–µ, —Ç–∞–∫ –∫–∞–∫ –±—É–¥–µ–º —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –¥—É–±–ª–∏ –∏ —á—É–∂–∏–µ –º–∞–≥–∞–∑–∏–Ω—ã
        fetch_multiplier = 4
        fetch_k = int(top_k * fetch_multiplier)

        results = collection.query(
            query_embeddings=[vector],
            n_results=fetch_k
        )

        # Chroma –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É: {'ids': [[]], 'metadatas': [[]], 'distances': [[]]}
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        if not results['ids'] or not results['ids'][0]:
            return ""

        # 4. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è
        context_text = ""
        found_count = 0

        # üî• –ú–Ω–æ–∂–µ—Å—Ç–≤–æ –¥–ª—è –∑–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è —É–∂–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π (–∞–Ω—Ç–∏-–¥—É–±–ª—å)
        seen_names = set()

        # –î–∞–Ω–Ω—ã–µ –ø–µ—Ä–≤–æ–≥–æ (–∏ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ) –∑–∞–ø—Ä–æ—Å–∞
        metadatas_list = results['metadatas'][0]
        distances_list = results['distances'][0]  # –ß–µ–º –º–µ–Ω—å—à–µ, —Ç–µ–º –ª—É—á—à–µ

        # --- –ü–û–î–ì–û–¢–û–í–ö–ê –°–ü–ò–°–ö–ê –†–ê–ó–†–ï–®–ï–ù–ù–´–• ID ---
        target_ids_set = set()
        if allowed_magazine_ids is not None:
            if isinstance(allowed_magazine_ids, int):
                target_ids_set.add(str(allowed_magazine_ids))
            else:
                # –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω —Å–ø–∏—Å–æ–∫ [1, 5], –ø—Ä–µ–≤—Ä–∞—â–∞–µ–º –≤ set —Å—Ç—Ä–æ—á–µ–∫ {"1", "5"}
                target_ids_set = set(str(x) for x in allowed_magazine_ids)

        for i, meta in enumerate(metadatas_list):
            if found_count >= top_k:
                break

            # --- üî• –ù–û–í–ê–Ø –§–ò–õ–¨–¢–†–ê–¶–ò–Ø (–û–¥–∏–Ω –∏–ª–∏ –°–ø–∏—Å–æ–∫) ---
            # –í update_vectors –º—ã —Å–æ—Ö—Ä–∞–Ω—è–ª–∏ "magazine_ids_str": "1,2,5"
            if target_ids_set:
                owners_str = meta.get("magazine_ids_str", "")
                owners_list = owners_str.split(",")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ: –µ—Å—Ç—å –ª–∏ —Ö–æ—Ç—å –æ–¥–∏–Ω –Ω–∞—à ID —Å—Ä–µ–¥–∏ –≤–ª–∞–¥–µ–ª—å—Ü–µ–≤?
                # –ï—Å–ª–∏ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –Ω–µ—Ç (–º–Ω–æ–∂–µ—Å—Ç–≤–æ –ø—É—Å—Ç–æ–µ) -> –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                if not (set(owners_list) & target_ids_set):
                    continue

            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            name = meta.get('name', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')

            # --- üî• –ó–ê–©–ò–¢–ê –û–¢ –î–£–ë–õ–ï–ô ---
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è: —É–±–∏—Ä–∞–µ–º —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã, –ø—Ä–æ–±–µ–ª—ã, –ø—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
            clean_name = re.sub(r'[^\w\s]', '', name).lower().strip()

            if clean_name in seen_names:
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º, –µ—Å–ª–∏ —Ç–∞–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —É–∂–µ –±—ã–ª–æ

            seen_names.add(clean_name)  # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º

            # --- –°–ë–û–†–ö–ê –û–¢–í–ï–¢–ê ---
            price = meta.get('price', '–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞')
            url = meta.get('url', '#')
            # –û–±—Ä–µ–∑–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ
            desc = meta.get('description', '')[:3000]

            # üî• –í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–ê –†–ï–õ–ï–í–ê–ù–¢–ù–û–°–¢–¨ üî•
            # –í Chroma —á–µ–º –º–µ–Ω—å—à–µ distance, —Ç–µ–º –ª—É—á—à–µ (0 = –∫–æ–ø–∏—è).
            # –ü—Ä–µ–≤—Ä–∞—â–∞–µ–º –≤ % —Å—Ö–æ–∂–µ—Å—Ç–∏: (1 - distance) * 100
            dist = distances_list[i]
            # –ó–∞—â–∏—Ç–∞ –æ—Ç –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö —á–∏—Å–µ–ª (–µ—Å–ª–∏ –≤–µ–∫—Ç–æ—Ä—ã —Å—Ç—Ä–∞–Ω–Ω—ã–µ), —Ö–æ—Ç—è –æ–±—ã—á–Ω–æ distance <= 1
            similarity = max(0.0, 1.0 - dist)
            relevance_percent = int(similarity * 100)

            context_text += (
                f"- <b>{name}</b>\n"
                f"  –¶–µ–Ω–∞: {price} —Ä—É–±.\n"
                f"  –°—Å—ã–ª–∫–∞: {url}\n"
                f"  –û–ø–∏—Å–∞–Ω–∏–µ: {desc}...\n"
                f"  <i>(–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {relevance_percent}%)</i>\n\n"
            )
            found_count += 1

        return context_text

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ ChromaDB: {e}")
        return ""
